---
name: LLM Client
status: open
created: 2025-12-22T03:28:32Z
updated: 2025-12-22T03:32:46Z
github: https://github.com/1psychoQAQ/verdict-agent/issues/3
depends_on: [2]
parallel: false
conflicts_with: []
---

# Task: LLM Client

## Description

Implement a unified LLM client interface that abstracts OpenAI and Anthropic APIs behind a common interface. Include retry logic, error handling, and JSON response parsing.

## Acceptance Criteria

- [ ] `LLMClient` interface defined with `Complete(prompt string) (string, error)`
- [ ] OpenAI implementation using official Go SDK or HTTP client
- [ ] Anthropic implementation using HTTP client
- [ ] Provider selection via environment variable
- [ ] Retry logic (3 attempts) with exponential backoff
- [ ] Timeout handling (configurable, default 5 minutes per call)
- [ ] JSON extraction from LLM responses

## Technical Details

### Interface Design
```go
type LLMClient interface {
    Complete(ctx context.Context, prompt string) (string, error)
    CompleteJSON(ctx context.Context, prompt string, schema any) error
}

type Config struct {
    Provider    string // "openai" or "anthropic"
    APIKey      string
    Model       string // "gpt-4" or "claude-3-opus"
    MaxRetries  int
    Timeout     time.Duration
}
```

### File Location
`internal/agent/llm.go`

### Error Types
```go
var (
    ErrRateLimited = errors.New("rate limited")
    ErrTimeout     = errors.New("request timeout")
    ErrInvalidJSON = errors.New("invalid JSON in response")
)
```

### JSON Extraction
- Parse LLM response for JSON block (between ```json and ```)
- Validate against expected schema
- Return structured error if validation fails

## Dependencies

- [ ] Task #2 (Project Setup) - config loading

## Effort Estimate

- Size: M
- Hours: 4-6
- Parallel: false (blocks agent tasks)

## Definition of Done

- [ ] Both OpenAI and Anthropic clients implemented
- [ ] Unit tests with mock HTTP responses
- [ ] Retry logic tested
- [ ] JSON extraction works reliably
- [ ] Provider switch via env var verified
